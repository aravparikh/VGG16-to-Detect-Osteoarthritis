import os
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from imblearn.over_sampling import ADASYN

# Function to load images and labels from subdirectories
def load_images_and_labels(base_path):
    images = []
    labels = []
    class_labels = sorted(os.listdir(base_path))  # Ensure the labels are sorted consistently
    for class_index, class_label in enumerate(class_labels):
        class_dir_path = os.path.join(base_path, class_label)
        if os.path.isdir(class_dir_path):
            for image_file in os.listdir(class_dir_path):
                image_path = os.path.join(class_dir_path, image_file)
                image = load_img(image_path, target_size=(224, 224))  # VGG16 uses 224x224 images
                image = img_to_array(image)
                image /= 255.0  # Normalize the image
                images.append(image)
                labels.append(class_index)
    
    return np.array(images), np.array(labels)

# Define the paths to your image directories
train_path = r'C:\Users\parik\OneDrive\OA\train'
val_path = r'C:\Users\parik\OneDrive\OA\val'
test_path = r'C:\Users\parik\OneDrive\OA\test'
num_classes = 5

# Load images and labels for training, validation, and testing
train_images, train_labels = load_images_and_labels(train_path)
val_images, val_labels = load_images_and_labels(val_path)
test_images, test_labels = load_images_and_labels(test_path)

# Convert labels to one-hot encoding
train_labels = to_categorical(train_labels, num_classes=num_classes)
val_labels = to_categorical(val_labels, num_classes=num_classes)
test_labels = to_categorical(test_labels, num_classes=num_classes)

# Flatten the image data to two dimensions
train_images_flat = train_images.reshape(train_images.shape[0], -1)
val_images_flat = val_images.reshape(val_images.shape[0], -1)
test_images_flat = test_images.reshape(test_images.shape[0], -1)

# Apply ADASYN oversampling on the flattened training data
adasyn = ADASYN()
X_resampled, y_resampled = adasyn.fit_resample(train_images_flat, train_labels)

# Reshape the resampled data back to the original image dimensions
X_resampled_images = X_resampled.reshape(-1, 224, 224, 3)

# Define the data augmentation parameters
augmentation_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Use data augmentation for training
train_generator = augmentation_datagen.flow(X_resampled_images, y_resampled, batch_size=32)

# Load the VGG16 model pre-trained on ImageNet data
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add custom layers on top of the base model
x = base_model.output
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = Dense(256, activation='relu')(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(num_classes, activation='softmax')(x)

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=len(X_resampled_images) // 32,
    validation_data=(val_images_flat.reshape(-1, 224, 224, 3), val_labels),
    epochs=5  # Adjust the number of epochs as needed
)

# Evaluate the model on the test dataset
test_loss, test_accuracy = model.evaluate(test_images_flat.reshape(-1, 224, 224, 3), test_labels)
print(f'Test Accuracy: {test_accuracy}')

# Save the model (optional)
model.save('vgg16_adasyn_augmentation_model.h5')
